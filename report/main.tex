\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin=1in]{geometry} %pour eviter d'avoir des marges ridicules
\usepackage{mathtools,amsmath,amsthm,amssymb,amsmath}
\usepackage{placeins}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{natbib}
\usepackage{bm}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[table]{xcolor}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\title{PROJ - Calcul de Plus Courts Chemins Robuste}
\author{Arthur Divanovic, Axel Navarro}

\begin{document}

\maketitle



\newpage
\tableofcontents

\newpage 
\section{Exercice 1: Modélisation Papier}

\subsection{Question 1.1: Modélisation du problème statique}

Pour modéliser le problème statique, nous allons attribuer les variables de décision $x$ à chaque arête $ij \in A$ telles que:
$$  x_{ij} = 
\begin{cases}
  1 \text{, si l'arête $ij$ est sélectionnée} \\
    0 \text{ sinon}
\end{cases}$$
Le problème de plus court chemin dans le cas statique peut se formuler de la façon suivante:

\begin{align}
    \min_{x \in \{0,1\}^{|A|}} & \sum_{ij \in A} d_{ij} x_{ij} && \notag \\
    \textbf{s.t: }  &\sum_{j: ij \in A} x_{ij} = \sum_{j: ji \in A} x_{ji} && \forall i \in V \setminus{\{s,t\}} \label{eq:constraint1} \\
    &\sum_{i: is \in A} x_{is} = 0 \label{eq:constraint3} \\
    &\sum_{j: sj \in A} x_{sj} = 1 \label{eq:constraint4} \\
    &\sum_{i: ip \in A} x_{ip} = 1 \label{eq:constraint5} \\
    &\sum_{j: pj \in A} x_{pj} = 0 \label{eq:constraint6} \\
    &\sum_{ij \in A} x_{ij}(p_i + p_j) + p_s + p_t \leq 2S \label{eq:constraint7}
\end{align}

Étant donné le choix des variables $x$, la longueur d'un chemin s'écrit bien $\sum_{(i,j) \in A} d_{i,j} x_{i,j}$, qui est la somme des coûts d'emprunt des arêtes sélectionnées. Il reste à s'assurer que un tel choix de $x$ définit bien un chemin de $s$ à $t$.
\\
\\
La contrainte (\ref{eq:constraint1}) assure que les arrêtes sélectionnées par la variable $x$ forment bien un chemin par conservation du flot.
\\
\\
Sachant que les chemins admissibles commencent par $s$, la contrainte (\ref{eq:constraint3}) assure que aucune arête sélectionnée n'arrive en $s$ et (\ref{eq:constraint4}) assure que exactement une arête partant de $s$ est selectionnée. De même, les chemins se terminent en $p$, ce qui est assuré par (\ref{eq:constraint5}) et (\ref{eq:constraint6}).
\\
Enfin, (\ref{eq:constraint7}) assure que le poids du chemin considéré est inférieur à $S$. Le facteur 2 provient du fait que l'on somme deux fois les poids des sommets $i$ différents de $s$ et $t$.

\subsection{Question 1.2 : Modélisation du problème robuste}

Pour le problème robuste, le paramètre $d$ peut désormais prendre des valeurs dans:
\[
d \in \mathcal{U}^{1} := \left\{(d^{1}_{ij} = d_{ij}(1 + \delta^{1}_{ij}))_{ij \in A} \ \middle|\ \ \sum_{ij \in A} \delta^{1}_{ij} \leq d_1, \delta^{1}_{ij} \in [0, D_{ij}] \ \forall ij \in A\right\}.
\]
On pose:
\[
\Delta^{1} := \left\{(\delta^{1}_{ij})_{ij \in A} \ \middle|\ \ \sum_{ij \in A} \delta^{1}_{ij} \leq d_1, \delta^{1}_{ij} \in [0, D_{ij}] \ \forall ij \in A\right\}.
\]
De même, le paramètre $p$ peut désormais prendre des valeurs dans:
\[
p \in \mathcal{U}^{2} := \left\{(p^{2}_{i} = p_{i} + \delta^{2}_{i} \hat{p_i})_{i \in V} \ \middle|\ \ \sum_{i \in V} \delta^{2}_{i} \leq d_2, \delta^{2}_{i} \in [0, 2] \ \forall i \in V\right\}.
\]
On pose de même:
\[
\Delta^{2} := \left\{(\delta^{2}_{i})_{i \in V} \ \middle|\ \ \sum_{i \in V} \delta^{2}_{i} \leq d_2, \delta^{2}_{i} \in [0, 2] \ \forall i \in V\right\}.
\]
En prenant en compte cette nouvelle modélisation, la fonction objectif devient:
$$\sum_{ij \in A} d_{ij} x_{ij} + d_{ij} \delta_{ij}^{1} x_{ij}.$$
Du côté des contraintes, seule la contrainte (\ref{eq:constraint7}) est affectée par l'incertitude sur $p$. Cette contrainte se réécrit:
$$\sum_{ij \in A} x_{ij}(p_i + p_j + \delta_{i}^{2} \hat{p_i} + \delta_{j}^{2} \hat{p_j}) + p_s + \delta_{s}^{2} \hat{p_s} + p_t + \delta_{t}^{2} \hat{p_t} \leq 2S.$$
Les autres contraintes (\ref{eq:constraint1}) à (\ref{eq:constraint6}) ne sont pas affectées par cette nouvelle modélisation.
\\
\\
La modélisation robuste partant du principe que la réalisation de l'incertitude observée est le pire cas possible, l'objectif du problème devient donc en mettant tout bout à bout:

\begin{align}
  \min_{x \in \{0,1\}^{|A|}} \max_{\delta^{1} \in \Delta^{1}} & \sum_{ij \in A} d_{ij} x_{ij} + d_{ij} \delta_{ij}^{1} x_{ij} && \notag \\
  \textbf{s.t: }  & (\ref{eq:constraint1}) \quad (\ref{eq:constraint3}) \quad (\ref{eq:constraint4}) \quad (\ref{eq:constraint5}) \quad (\ref{eq:constraint6}) \notag \\
  &\sum_{ij \in A} x_{ij}(p_i + p_j + \delta_{i}^{2} \hat{p_i} + \delta_{j}^{2} \hat{p_j}) + p_s + \delta_{s}^{2} \hat{p_s} + p_t + \delta_{t}^{2} \hat{p_t} \leq 2S & \forall \delta^{2} \in \Delta^{2} \tag{6'} \label{eq:constraint7prime}
\end{align}


\subsection{Question 1.3 : Résolution par plans coupants et LazyCallback}

\subsubsection{Reformulation de l'objectif}

En posant $\eta$ une nouvelle variable tel que :

\begin{align}
  \eta \geq \sum_{ij \in A} d_{ij} \delta_{ij}^{1} x_{ij}, \ \forall \delta^{1} \in \Delta^{1}. \notag
\end{align}

On peut reformuler l'objectif du problème robuste : 

\begin{align}
  \min_{x, \hspace{1px} \hspace{1px} \hspace{1px} \eta} & \sum_{ij \in A} d_{ij} x_{ij} + \eta && \notag \\
  \textbf{s.t: }  & (\ref{eq:constraint1}) \quad (\ref{eq:constraint3}) \quad (\ref{eq:constraint4}) \quad (\ref{eq:constraint5}) \quad (\ref{eq:constraint6}) \quad (\ref{eq:constraint7prime}) \notag \\
  & \eta \geq \sum_{ij \in A} d_{ij} \delta_{ij}^{1} x_{ij} & \forall \delta^{1} \in \Delta^{1} \label{eq:constraint12} \\
  & \eta \geq 0 \notag \\
  & x \in \{0,1\}^{|A|} \notag
\end{align}

\subsubsection{Définition initale de $\mathcal{U}^{1*}$ et $\mathcal{U}^{2*}$}

Pour la resolution par plans coupants, nous devons définir les ensembles $\mathcal{U}^{1*}$ et $\mathcal{U}^{2*}$ qui seront initialement considérés.
Nous les choisissons vides : 

\begin{align}
  \mathcal{U}^{1*} = \emptyset \quad \quad \quad \mathcal{U}^{2*} = \emptyset \notag
\end{align}

\subsubsection{Sous-problèmes}
Le problème maître s'écrit :

\begin{align}
  \min_{x, \hspace{1px} \eta } & \sum_{ij \in A} d_{ij} x_{ij} + \eta && \tag{MP} \label{eq:master-problem} \\
  \textbf{s.t: } & (\ref{eq:constraint1}) \quad (\ref{eq:constraint3}) \quad (\ref{eq:constraint4}) \quad (\ref{eq:constraint5}) \quad (\ref{eq:constraint6}) \notag \\
  & \eta \geq \sum_{ij \in A} d_{ij} \delta_{ij}^{1} x_{ij} & \forall \delta^{1} \in \mathcal{U}^{1*} \\
  & \sum_{ij \in A} x_{ij}(p_i + p_j + \delta_{i}^{2} \hat{p_i} + \delta_{j}^{2} \hat{p_j}) + p_s + \delta_{s}^{2} \hat{p_s} + p_t + \delta_{t}^{2} \hat{p_t} \leq 2S & \forall \delta^{2} \in \mathcal{U}^{2*} \\
  & \eta \geq 0 \notag \\
  & x \in \{0,1\}^{|A|} \notag
\end{align}

La résolution de (\ref{eq:master-problem}) nous donne une solution ($x^*, \eta^*$).

On résout ensuite les deux sous-problèmes (\ref{eq:sous-pb-a}) et (\ref{eq:sous-pb-b}): 
\begin{align}
  \max_{\delta^{1} \geq 0} & \sum_{ij \in A} d_{ij} \delta_{ij}^{1} x^*_{ij} - \eta^* \tag{SP-A} \label{eq:sous-pb-a}\\
  \textbf{s.t: } & \sum_{ij \in A} \delta_{ij}^{1} \leq d_1 \notag \\
  &\delta_{ij}^{1} \leq D_{ij} & \forall ij \in A \notag \\
\end{align}

\begin{align}
  \max_{\delta^{2} \geq 0} & \sum_{ij \in A} x^*_{ij}(p_i + p_j + \delta_{i}^{2} \hat{p_i} + \delta_{j}^{2} \hat{p_j}) + p_s + \delta_{s}^{2} \hat{p_s} + p_t + \delta_{t}^{2} \hat{p_t} - 2S \tag{SP-B} \label{eq:sous-pb-b}\\
  \textbf{s.t: } & \sum_{i \in V} \delta^{2}_{i} \leq d_2 \notag \\
  &\delta^{2}_{i} \leq 2 & \forall i \in V \notag
\end{align}

La résolution de (\ref{eq:sous-pb-a}) et (\ref{eq:sous-pb-b}) nous donne deux solutions optimales $\delta^{1*}$ et $\delta^{2*}$. \\
\\
Si la valeur optimale de l'objectif de (\ref{eq:sous-pb-a}) est strictement positive, alors on ajoute $\delta^{1*}$ à $\mathcal{U}^{1*}$. \\
Si la valeur optimale de l'objectif de (\ref{eq:sous-pb-b}) est strictement positive, alors on ajoute $\delta^{2*}$ à $\mathcal{U}^{2*}$.

\subsubsection{Condition d'optimalité du problème maitre}
Une solution du problème maitre ($x^*, \eta^*$) est optimale si les valeurs optimales des objectifs de (\ref{eq:sous-pb-a}) et (\ref{eq:sous-pb-b}) sont négatives (au sens large) pour ($x^*, \eta^*$).

\subsubsection{Coupes ajoutées}

Pour un  $\delta^{1*}$ et $\delta^{2*}$ ajoutés respectivement aux ensembles $\mathcal{U}^{1*}$ et $\mathcal{U}^{2*}$. Les coupes du problème maitre sont de la forme : 
\begin{align}
  & \eta \geq \sum_{ij \in A} d_{ij} \delta_{ij}^{1*} x_{ij} \notag \\
  & \sum_{ij \in A} x_{ij}(p_i + p_j + \delta_{i}^{2*} \hat{p_i} + \delta_{j}^{2*} \hat{p_j}) + p_s + \delta_{s}^{2*} \hat{p_s} + p_t + \delta_{t}^{2*} \hat{p_t} \leq 2S \notag
\end{align}


\subsection{Question 1.4 : Résolution par dualisation}

\subsubsection{Reformulation de l'objectif}

L'objectif du problème robuste de la Question 1.2 peut se reformuler:
$$ \min_{x \in \{0,1\}^{|A|}} \left\{ \sum_{ij \in A} d_{ij} x_{ij} + \max_{\delta^{1} \geq 0} d_{ij} \delta_{ij}^{1} x_{ij} \right\},$$
auquel s'ajoute les contraintes de la Question 1.2.

\subsubsection{Sous problème lié à $\delta^{1}$}

Le problème interne lié aux variables $\delta^{1}_{ij}$ est donc:

\begin{align}
  \max_{\delta^{1}\geq 0} & \sum_{ij \in A} d_{ij} \delta_{ij}^{1} x_{ij} \tag{SP1} \label{eq:sous-pb-delta1}  \\
  \textbf{s.t: } &\sum_{ij \in A} \delta_{ij}^{1} \leq d_1 \notag \\
  &\delta_{ij}^{1} \leq D_{ij} && \forall ij \in A \notag
\end{align}

\subsubsection{Dualisation du sous problème lié à $\delta^{1}$}

Nous allons attribuer la variable duale $\alpha \geq 0$ à la première contrainte de (\ref{eq:sous-pb-delta1}). Nous attribuerons aussi aux constraintes indéxées par $A$ les variables duales $\beta_{ij} \geq 0$.
\\
\\
Le problème (\ref{eq:sous-pb-delta1}) est linéaire et admet une solution admissible triviale telle que $\forall ij, \delta^{1}_{ij} = 0$. Par dualité forte, ce problème peut se réécrire:
\begin{align}
  \min_{\alpha, \beta \geq 0} & \alpha d_1  + \sum_{ij \in A} \beta_{ij} D_{ij} \tag{D-SP1} \label{eq:dual-sous-pb-delta1}  \\
  \textbf{s.t: } &d_{ij} x_{ij} \leq \alpha + \beta_{ij} && \forall ij \in A \notag
\end{align}

\subsubsection{Reformulation de la contrainte robuste}

La contrainte robuste (\ref{eq:constraint7prime}), se réécrit:

\begin{equation}
\label{eq:ref_contrainte_robuste}
  \sum_{ij \in A} x_{ij}(p_i + p_j + \delta_{i}^{2} \hat{p_i} + \delta_{j}^{2} \hat{p_j}) + p_s + p_t + \delta_{s}^{2} \hat{p_s} + \delta_{t}^{2} \hat{p_t} \leq 2S,\ \forall \delta^{2} \in \Delta^{2}.
\end{equation}


\subsubsection{Sous problème lié à $\delta^{2}$}

Le fait que la contrainte (\ref{eq:ref_contrainte_robuste}) doit être vérifiée pour tout $\delta^{2}$ peut se réécrire en faisant apparaître un problème de maximisation sur $\delta^{2}$.
\begin{align}
  \sum_{ij \in A} x_{ij} (p_i + p_j) + p_s + p_t + 
    \max_{\delta^{2} \geq 0} & \sum_{ij \in A} x_{ij}(\delta^{2}_{i} \hat{p_i} + \delta^{2}_{j} \hat{p_j}) + \delta^{2}_{s} \hat{p_s} + \delta^{2}_{t} \hat{p_t} \leq 2S \\
     \textbf{s.t: } & \sum_{i \in V} \delta^{2}_{i} \leq d_2 \notag \\
     & \delta^{2}_{i} \leq 2 && \forall i \in V \notag
\end{align}


\subsubsection{Dualisation du sous problème lié à $\delta^{2}$}

Réécrivons le sous-problème sur la variable $\delta^{2}$ ci-dessus:

\begin{align}
    \max_{\delta^{2} \geq 0} & \sum_{ij \in A} x_{ij}(\delta^{2}_{i} \hat{p_i} + \delta^{2}_{j} \hat{p_j}) + \delta^{2}_{s} \hat{p_s} + \delta^{2}_{t} \hat{p_t} \tag{SP2} \label{eq:sous-prob-2}\\
     \textbf{s.t: } & \sum_{i \in V} \delta^{2}_{i} \leq d_2 \notag \\
     & \delta^{2}_{i} \leq 2 && \forall i \in V \notag
\end{align}

Dans le problème de maximisation (\ref{eq:sous-prob-2}), nous attribuerons à la première contrainte la variable duale $\gamma \geq 0$, ainsi que les variables duales $\sigma_{i} \geq 0$ pour les contraintes indexées par $V$. En dualisant ce problème, nous obtenons:
\begin{align}
  \min_{\gamma, \sigma \geq 0} & \gamma d_2 + 2 \sum_{i \in V} \sigma_i \tag{D-SP2} \label{eq:dual-sous-prob-2}\\
   \textbf{s.t: } & \sum_{j: ij \in A} x_{ij} \hat{p_i} + \sum_{j: ji \in A} x_{ji} \hat{p_i} \leq \gamma + \sigma_i && \forall i \in V \setminus{\{s,t\}} \notag \\
   & \sum_{j: sj \in A} x_{sj} \hat{p_s} + \hat{p_s} \leq \gamma + \sigma_s \notag \\
   & \sum_{j: jt \in A} x_{jt} \hat{p_t} + \hat{p_t} \leq \gamma + \sigma_t \notag
\end{align}
Ainsi, la contrainte (\ref{eq:constraint7prime}) est vérifiée si et seulement si: 
$$\exists \gamma, \sigma \geq 0 : 
\begin{cases}
  \sum_{ij \in A} x_{ij} (p_i + p_j) + p_s + p_t + \gamma d_2 + 2 \sum_{i \in V} \sigma_i  \leq 2S\\
  \sum_{j: ij \in A} x_{ij} \hat{p_i} + \sum_{j: ji \in A} x_{ji} \hat{p_i} \leq \gamma + \sigma_i, \ \forall i \in V \setminus{\{s,t\}}  \\
   \sum_{j: sj \in A} x_{sj} \hat{p_s} + \hat{p_s} \leq \gamma + \sigma_s  \\
   \sum_{j: jt \in A} x_{jt} \hat{p_t} + \hat{p_t} \leq \gamma + \sigma_t 
\end{cases}
$$

\subsubsection{Reformulation du problème robuste}

En mettant ensemble les deux reformulations des sous-problèmes sur les variables $\delta^{1}$ et $\delta^{2}$ obtenues précédemment, le problème robuste se reformule en:

\begin{align}
  \min_{x, \alpha, \beta, \gamma, \sigma} & \ \ \ \sum_{ij \in A} d_{ij} x_{ij} + \alpha d_1 + \sum_{ij \in A} \beta_{ij} D_{ij} && \notag \\
  \textbf{s.t: }  &\sum_{j: ij \in A} x_{ij} = \sum_{j: ji \in A} x_{ji} && \forall i \in V \setminus{\{s,t\}} \notag \\
  &\sum_{i: is \in A} x_{is} = 0 \notag \\
  &\sum_{j: sj \in A} x_{sj} = 1 \notag \\
  &\sum_{i: ip \in A} x_{ip} = 1 \notag \\
  &\sum_{j: pj \in A} x_{pj} = 0 \notag \\
  &\sum_{ij \in A} x_{ij} (p_i + p_j) + p_s + p_t + \gamma d_2 + 2 \sum_{i \in V} \sigma_i \leq 2S \notag \\
  & \sum_{j: ij \in A} x_{ij} \hat{p_i} + \sum_{j: ji \in A} x_{ji} \hat{p_i} \leq \gamma + \sigma_i && \forall i \in V \setminus{\{s,t\}} \\
  & \hat{p_s}(1 + \sum_{j: sj \in A} x_{sj})  \leq \gamma + \sigma_s \\
  & \hat{p_t} (1 + \sum_{j: jt \in A} x_{jt}) \leq \gamma + \sigma_t \\
  & d_{ij} x_{ij} \leq \alpha + \beta{ij} && \forall ij \in A 
\end{align}

On retrouve ainsi un programme linéaire en nombre entiers, équivalent au problème robuste.



% \newpage

% \section{Exercice 2: Résolution Numérique}

% \subsection{Question 2.1}

% \subsection{Question 2.2}

% \subsection{Question 2.3}




% \newpage
% \section*{Conclusion}
% \addcontentsline{toc}{section}{Conclusion}



% \vspace{2cm}
% Le code correspondant à ce projet est disponible sur le lien GitHub ci-dessous:
% \\
% \begin{center}
% https://github.com/ArthurDivanovic/
% \end{center}



% \newpage
% \bibliography{Bibliography.bib}
% \bibliographystyle{plainnat} %pour la bibliography
% % \bibliographystyle{unsrt}

\end{document}
